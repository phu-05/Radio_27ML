{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca16d27d",
   "metadata": {},
   "source": [
    "# Training a Quantized NN for Modulation Classification\n"
    "## Modified version of https://github.com/Xilinx/brevitas-radioml-challenge-21/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5962bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some general modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "import h5py as h5\n",
    "#from torchsummary import summary\n",
    "from sklearn.metrics import classification_report\n",
    "import brevitas \n",
    "import brevitas.quant as quant\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some general modules\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2408658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which GPU to use (if available)\n",
    "gpu = 0\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.device(gpu)\n",
    "    print(\"Using GPU %d\" % gpu)\n",
    "else:\n",
    "    gpu = None\n",
    "    print(\"Using CPU only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-chrome",
   "metadata": {},
   "source": [
    "# The RadioML 2021 Dataset <a id='load_dataset'></a>\n",
    "\n",
    "The dataset comes in hdf5 format and exhibits the following structure:\n",
    "- 27 modulations\n",
    "- 26 SNRs per modulation (-20 dB through +30 dB in steps of 2)\n",
    "- 4096 frames per modulation-SNR combination\n",
    "- 1024 complex time-series samples per frame\n",
    "- Samples as floating point in-phase and quadrature (I/Q) components, resulting in a (1024,2) frame shape\n",
    "- 2.875.392 frames in total\n",
    "- Value is in int8 [-128, 127]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f18d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if dataset is present\n",
    "import os.path\n",
    "dataset_path = \"datasets/RADIOML_2021_07_INT8/RADIOML_2021_07_INT8.hdf5\"\n",
    "os.path.isfile(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data loader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "\n",
    "class radioml_21_dataset(Dataset):\n",
    "    def __init__(self, dataset_path):\n",
    "        super(radioml_21_dataset, self).__init__()\n",
    "        h5_file = h5py.File(dataset_path,'r')\n",
    "        self.data = h5_file['X']\n",
    "        self.mod = np.argmax(h5_file['Y'], axis=1) # comes in one-hot encoding\n",
    "        self.snr = h5_file['Z'][:,0]\n",
    "        self.len = self.data.shape[0]\n",
    "\n",
    "        self.mod_classes = [\n",
    "                \"OOK\",\n",
    "                \"4ASK\",\n",
    "                \"8ASK\",\n",
    "                \"BPSK\",\n",
    "                \"QPSK\",\n",
    "                \"8PSK\",\n",
    "                \"16PSK\",\n",
    "                \"32PSK\",\n",
    "                \"16APSK\",\n",
    "                \"32APSK\",\n",
    "                \"64APSK\",\n",
    "                \"128APSK\",\n",
    "                \"16QAM\",\n",
    "                \"32QAM\",\n",
    "                \"64QAM\",\n",
    "                \"128QAM\",\n",
    "                \"256QAM\",\n",
    "                \"AM-SSB-WC\",\n",
    "                \"AM-SSB-SC\",\n",
    "                \"AM-DSB-WC\",\n",
    "                \"AM-DSB-SC\",\n",
    "                \"FM\",\n",
    "                \"GMSK\",\n",
    "                \"OQPSK\",\n",
    "                \"BFSK\",\n",
    "                \"4FSK\",\n",
    "                \"8FSK\",\n",
    "            ]\n",
    "        self.num_classes=len(self.mod_classes)\n",
    "        # print(np.unique(self.snr))\n",
    "        # print(self.data.shape)\n",
    "        # print(np.min(self.data),'   ',np.max(self.data),'  ',self.data.dtype)\n",
    "        self.snr_classes = np.arange(-20., 32., 2) # -20dB to 30dB, with step of 2 --> 26 snrs\n",
    "\n",
    "        # do not touch this seed to ensure the prescribed train/test split!\n",
    "        np.random.seed(2021)\n",
    "\n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        for mod in range(0, len(self.mod_classes)): # all modulations (0 to 26)\n",
    "            for snr_idx in range(0, 26): # all SNRs (0 to 25 = -20dB to +30dB)\n",
    "                # 'X' holds frames strictly ordered by modulation and SNR\n",
    "                #4096 is the number of frames per modulation-snr pair combination. 2875392 / (27*26) = 4096\n",
    "                start_idx = 26*4096*mod + 4096*snr_idx \n",
    "                indices_subclass = list(range(start_idx, start_idx+4096))\n",
    "                \n",
    "                # 90%/10% training/test split, applied evenly for each mod-SNR pair\n",
    "                split = int(np.ceil(0.1 * 4096)) \n",
    "                np.random.shuffle(indices_subclass)\n",
    "                train_indices_subclass = indices_subclass[split:]\n",
    "                test_indices_subclass = indices_subclass[:split]\n",
    "                \n",
    "                # you could train on a subset of the data, e.g. based on the SNR\n",
    "                # here we use all available training samples\n",
    "                if snr_idx >= 0:\n",
    "                    train_indices.extend(train_indices_subclass)\n",
    "                test_indices.extend(test_indices_subclass)\n",
    "                \n",
    "        self.train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "        self.test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # transpose frame into Pytorch channels-first format (NCL = -1,2,1024)\n",
    "        return self.data[idx].transpose(), self.mod[idx], self.snr[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "dataset = radioml_21_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect a frame\n",
    "mod = 26 # 0 to 26\n",
    "snr_idx = 25 # 0 to 25 = -20dB to +30dB\n",
    "sample = 123 # 0 to 4095\n",
    "#-----------------------#\n",
    "idx = 26*4096*mod + 4096*snr_idx + sample\n",
    "data, mod, snr = dataset.data[idx], dataset.mod[idx], dataset.snr[idx]\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(data)\n",
    "print(\"Modulation: %s, SNR: %.1f dB, Index: %d\" % (dataset.mod_classes[mod], snr, idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccccb1d",
   "metadata": {},
   "source": [
    "# Define the QNN Model <a id='define_model'></a>\n",
    "\n",
    "<div>\n",
    "<img align=\"right\" width=\"274\" height=\"418\" src=\"attachment:VGG10_small.png\">\n",
    "</div>\n",
    "\n",
    "As a simple example, we will create a quantized version of the \"VGG10\" CNN architecture proposed by the dataset authors in [Over-the-Air Deep Learning Based Radio Signal Classification](https://arxiv.org/pdf/1712.04578.pdf).\n",
    "\n",
    "Quantizing a sequential pytorch model is straightforward with Brevitas. Relevant `torch.nn` layers are simply replaced by their `brevitas.nn` counterparts, which add customizable input, output, or parameter quantization. Regular Torch layers, especially those that are invariant to quantization (e.g. BatchNorm or MaxPool), can be mixed and matched with Brevitas layers.\n",
    "\n",
    "As a baseline, we apply 8-bit quantization to the activations and weights of every layer, except for the final classification output. The input data is quantized to 8 bits with a dedicated quantization layer. Instead of letting Brevitas determine the quantization scale automatically, we set a fixed quantization range (-2.0, 2.0) based on analysis of the whole dataset. Except for two outlier classes (both single-sideband (SSB) modulations), the vast majority of samples (98.3%) at +30 dB fall within this range and will thus not be clipped.\n",
    "\n",
    "For more information on Brevitas you can turn to these resources:\n",
    "- [GitHub repository](https://github.com/Xilinx/brevitas)\n",
    "- [Tutorial notebooks](https://github.com/Xilinx/brevitas/tree/master/notebooks)\n",
    "- [Example models](https://github.com/Xilinx/brevitas/tree/master/src/brevitas_examples)\n",
    "- Public discussion in the [Brevitas Gitter channel](https://gitter.im/xilinx-brevitas/community)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-freight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant import Int8Bias\n",
    "from brevitas.inject.enum import ScalingImplType\n",
    "from brevitas.inject.defaults import Int8ActPerTensorFloatMinMaxInit\n",
    "\n",
    "# Adjustable hyperparameters\n",
    "input_bits = 8\n",
    "a_bits = 4\n",
    "w_bits = 4\n",
    "filters_conv = 64\n",
    "filters_dense = 128\n",
    "\n",
    "# Setting seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "class InputQuantizer(Int8ActPerTensorFloatMinMaxInit):\n",
    "    bit_width = input_bits\n",
    "    #Normalizing the input range to [0,1]\n",
    "    #Because our input is int8 [-128, 127], we need to convert them to float32 [0.0, 1.0] for internal nodes to process. \n",
    "    min_val = -128.0\n",
    "    max_val = 127.0\n",
    "    scaling_impl_type = ScalingImplType.CONST # Fix the quantization range to [min_val, max_val]\n",
    "\n",
    "model_class = nn.Sequential(\n",
    "    # Input quantization layer\n",
    "    qnn.QuantHardTanh(act_quant=InputQuantizer),\n",
    "\n",
    "    qnn.QuantConv1d(2, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits,bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "\n",
    "    qnn.QuantConv1d(filters_conv, filters_conv, 3, padding=1, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_conv),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "    nn.MaxPool1d(2),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "\n",
    "    qnn.QuantLinear(filters_conv*8, filters_dense, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_dense),\n",
    "    qnn.QuantReLU(bit_width=a_bits),\n",
    "\n",
    "    qnn.QuantLinear(filters_dense, filters_dense, weight_bit_width=w_bits, bias=False),\n",
    "    nn.BatchNorm1d(filters_dense),\n",
    "    qnn.QuantReLU(bit_width=a_bits, return_quant_tensor=True),\n",
    "\n",
    "    qnn.QuantLinear(filters_dense, 27, weight_bit_width=w_bits, bias=True, bias_quant=Int8Bias),\n",
    ")\n",
    "model=model_class\n",
    "\n",
    "import torchinfo\n",
    "print(torchinfo.summary(model_class,input_size=(1,2,1024)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-garage",
   "metadata": {},
   "source": [
    "# Train the QNN from Scratch <a id='train_model'></a>\n",
    "<span style=\"color:red\">Even with GPU acceleration, training will take multiple minutes per epoch!<br>You can skip this section and load a pre-trained model instead: [Load Pre-Trained Parameters](#load_trained_model)</span>\n",
    "\n",
    "First, we define basic train and test functions, which will be called for each training epoch. Training itself follows the usual Pytorch procedures, while Brevitas handles all quantization-specifics automatically in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5496ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train(model, train_loader, optimizer, criterion):\n",
    "    losses = []\n",
    "    # ensure model is in training mode\n",
    "    model.train()    \n",
    "\n",
    "    for (inputs, target, snr) in tqdm(train_loader, desc=\"Training Batches\", leave=False):   \n",
    "        if gpu is not None:\n",
    "            inputs = inputs.to('cuda')\n",
    "            target = target.to('cuda')\n",
    "                \n",
    "        # forward pass\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # backward pass + run optimizer to update weights\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # keep track of loss value\n",
    "        losses.append(loss.cpu().detach().numpy())\n",
    "           \n",
    "    return losses\n",
    "\n",
    "def test(model, test_loader):    \n",
    "    # ensure model is in eval mode\n",
    "    model.eval() \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "   \n",
    "    with torch.no_grad():\n",
    "        for (inputs, target, snr) in tqdm(test_loader, desc=\"Testing Batches\", leave=False):\n",
    "            if gpu is not None:\n",
    "                inputs = inputs.to('cuda')\n",
    "                target = target.to('cuda')\n",
    "            output = model(inputs)\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            y_true.extend(target.tolist()) \n",
    "            y_pred.extend(pred.reshape(-1).tolist())\n",
    "        \n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def display_loss_plot(losses, title=\"Training loss\", xlabel=\"Iterations\", ylabel=\"Loss\"):\n",
    "    x_axis = [i for i in range(len(losses))]\n",
    "    plt.plot(x_axis,losses)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf40cb8",
   "metadata": {},
   "source": [
    "Now we can start the training loop for a number of epochs.\n",
    "\n",
    "If you run into VRAM limitations of your system, it might help to decrease the `batch_size` and initial learning rate accordingly. To keep this notebook's resource footprint small, we do not pre-load the whole dataset into DRAM. You should adjust your own training code to take advantage of multiprocessing and available memory for maximum performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "num_epochs = 20\n",
    "\n",
    "data_loader_train = DataLoader(dataset, batch_size=batch_size, sampler=dataset.train_sampler)\n",
    "data_loader_test = DataLoader(dataset, batch_size=batch_size, sampler=dataset.test_sampler)\n",
    "\n",
    "if gpu is not None:\n",
    "    model = model.to('cuda')\n",
    "\n",
    "# loss criterion and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if gpu is not None:\n",
    "    criterion = criterion.to('cuda')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=1)\n",
    "\n",
    "running_loss = []\n",
    "running_test_acc = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        print('training')\n",
    "        loss_epoch = train(model, data_loader_train, optimizer, criterion)\n",
    "        print('testing')\n",
    "        test_acc = test(model, data_loader_test)\n",
    "        print(\"Epoch %d: Training loss = %f, test accuracy = %f\" % (epoch, np.mean(loss_epoch), test_acc))\n",
    "        running_loss.append(loss_epoch)\n",
    "        running_test_acc.append(test_acc)\n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977adfc8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training loss over epochs\n",
    "loss_per_epoch = [np.mean(loss_per_epoch) for loss_per_epoch in running_loss]\n",
    "display_loss_plot(loss_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c8939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot test accuracy over epochs\n",
    "acc_per_epoch = [np.mean(acc_per_epoch) for acc_per_epoch in running_test_acc]\n",
    "display_loss_plot(acc_per_epoch, title=\"Test accuracy\", ylabel=\"Accuracy [%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained parameters to disk\n",
    "Path(\"27ml_rf\").mkdir(exist_ok=True)\n",
    "torch.save(model.state_dict(), \"27ml_rf/model_trained.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6a3ab",
   "metadata": {},
   "source": [
    "# Load a Trained Model <a id='load_trained_model'></a>\n",
    "Alternatively, you can load the provided pre-trained model.\n",
    "It was trained for 20 epochs and reaches an overall accuracy of 59.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2423b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model_class\n",
    "model.load_state_dict(torch.load(\"27ml_rf/model_trained.pth\"))\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-blame",
   "metadata": {},
   "source": [
    "# Evaluate the Accuracy <a id='evaluate_accuracy'></a>\n",
    "The following cells visualize the test accuracy across different modulations and signal-to-noise ratios. Submissions for this problem statement must reach an overall accuracy of at least **56.0%**, so this should give you an idea what makes up this figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a fresh test data loader\n",
    "batch_size = 1024\n",
    "dataset = radioml_21_dataset(dataset_path)\n",
    "data_loader_test = DataLoader(dataset, batch_size=batch_size, sampler=dataset.test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on validation data\n",
    "y_exp = np.empty((0))\n",
    "y_snr = np.empty((0))\n",
    "y_pred = np.empty((0,len(dataset.mod_classes)))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(data_loader_test, desc=\"Batches\"):\n",
    "        inputs, target, snr = data\n",
    "        if gpu is not None:\n",
    "            inputs = inputs.cuda()\n",
    "        output = model(inputs)\n",
    "        y_pred = np.concatenate((y_pred,output.cpu()))\n",
    "        y_exp = np.concatenate((y_exp,target))\n",
    "        y_snr = np.concatenate((y_snr,snr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d5abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overall confusion matrix\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=90)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "conf = np.zeros([len(dataset.mod_classes),len(dataset.mod_classes)])\n",
    "confnorm = np.zeros([len(dataset.mod_classes),len(dataset.mod_classes)])\n",
    "for i in range(len(y_exp)):\n",
    "    j = int(y_exp[i])\n",
    "    k = int(np.argmax(y_pred[i,:]))\n",
    "    conf[j,k] = conf[j,k] + 1\n",
    "for i in range(0,len(dataset.mod_classes)):\n",
    "    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_confusion_matrix(confnorm, labels=dataset.mod_classes)\n",
    "\n",
    "cor = np.sum(np.diag(conf))\n",
    "ncor = np.sum(conf) - cor\n",
    "print(\"Overall Accuracy across all SNRs: %f\"%(cor / (cor+ncor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b63a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices at 4 different SNRs\n",
    "snr_to_plot = [-20,-4,+4,+30]\n",
    "plt.figure(figsize=(16,10))\n",
    "acc = []\n",
    "for snr in dataset.snr_classes:\n",
    "    # extract classes @ SNR\n",
    "    indices_snr = (y_snr == snr).nonzero()\n",
    "    y_exp_i = y_exp[indices_snr]\n",
    "    y_pred_i = y_pred[indices_snr]\n",
    " \n",
    "    conf = np.zeros([len(dataset.mod_classes),len(dataset.mod_classes)])\n",
    "    confnorm = np.zeros([len(dataset.mod_classes),len(dataset.mod_classes)])\n",
    "    for i in range(len(y_exp_i)):\n",
    "        j = int(y_exp_i[i])\n",
    "        k = int(np.argmax(y_pred_i[i,:]))\n",
    "        conf[j,k] = conf[j,k] + 1\n",
    "    for i in range(0,len(dataset.mod_classes)):\n",
    "        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    " \n",
    "    if snr in snr_to_plot:\n",
    "        plot, = np.where(snr_to_plot == snr)[0]\n",
    "        plt.subplot(221+plot)\n",
    "        plot_confusion_matrix(confnorm, labels=dataset.mod_classes, title=\"Confusion Matrix @ %d dB\"%(snr))\n",
    " \n",
    "    cor = np.sum(np.diag(conf))\n",
    "    ncor = np.sum(conf) - cor\n",
    "    acc.append(cor/(cor+ncor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f0670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy over SNR\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(dataset.snr_classes, acc, marker='o')\n",
    "plt.xlabel(\"SNR [dB]\")\n",
    "plt.xlim([-20, 30])\n",
    "plt.ylabel(\"Classification Accuracy\")\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.title(\"Classification Accuracy over SNR\")\n",
    "plt.grid()\n",
    "plt.title(\"Classification Accuracy over SNR\");\n",
    "\n",
    "print(\"Accuracy @ highest SNR (+30 dB): %f\"%(acc[-1]))\n",
    "print(\"Accuracy overall: %f\"%(np.mean(acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eda0e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy per modulation\n",
    "accs = []\n",
    "for mod in range((dataset.num_classes)):\n",
    "    accs.append([])\n",
    "    for snr in dataset.snr_classes:\n",
    "        indices = ((y_exp == mod) & (y_snr == snr)).nonzero()\n",
    "        y_exp_i = y_exp[indices]\n",
    "        y_pred_i = y_pred[indices]\n",
    "        cor = np.count_nonzero(y_exp_i == np.argmax(y_pred_i, axis=1))\n",
    "        accs[mod].append(cor/len(y_exp_i))\n",
    "        \n",
    "# Plot accuracy-over-SNR curve\n",
    "plt.figure(figsize=(12,8))\n",
    "for mod in range(dataset.num_classes):\n",
    "    if accs[mod][-1] < 0.95 or accs[mod][0] > 0.1:\n",
    "        color = None\n",
    "    else:\n",
    "        color = \"black\"\n",
    "    plt.plot(dataset.snr_classes, accs[mod], label=str(mod) + \": \" + dataset.mod_classes[mod], color=color)\n",
    "plt.xlabel(\"SNR [dB]\")\n",
    "plt.xlim([-20, 30])\n",
    "plt.ylabel(\"Classification Accuracy\")\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.title(\"Accuracy breakdown\")\n",
    "plt.grid()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d91c4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "from brevitas.export import export_qonnx,export_brevitas_onnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "import os \n",
    "import onnx\n",
    "\n",
    "Path(\"27ml_rf/models\").mkdir(exist_ok=True)\n",
    "model=model_class\n",
    "model.load_state_dict(torch.load(\"27ml_rf/model_trained.pth\"))\n",
    "model.to('cuda')\n",
    "\n",
    "model.eval()\n",
    "build_dir=\"27ml_rf/models\"\n",
    "export_path=f\"{build_dir}/radio_27ml_export.onnx\"\n",
    "export_qonnx(model.to('cuda'), torch.randn(1, 2, 1024).to('cuda'), export_path=export_path);\n",
    "#export_brevitas_onnx(model.cpu(),torch.randn(1, 2, 1024),export_path=export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2d2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "from qonnx.transformation.general import (\n",
    "    ConvertSubToAdd,\n",
    "    ConvertDivToMul,\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    SortGraph,\n",
    "    RemoveUnusedTensors,\n",
    "    GiveUniqueParameterTensors,\n",
    "    RemoveStaticGraphInputs,\n",
    "    ApplyConfig,\n",
    ")\n",
    "import onnx\n",
    "from onnx import TensorProto, helper\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "\n",
    "#Main goal is to skip the first multithreshold node.\n",
    "#The first multithreshold node is the quantizing data node.\n",
    "#Because on FPGA we will preprocess the data before forwarding through model, \n",
    "#we will remove the first multithreshold node.\n",
    "model = ModelWrapper(export_path)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model.save(f\"{build_dir}/radio_27ml_finn.onnx\")\n",
    "# tidy up\n",
    "finn_model = ModelWrapper(f\"{build_dir}/radio_27ml_finn.onnx\")\n",
    "\n",
    "finn_model = finn_model.transform(InferShapes())\n",
    "finn_model = finn_model.transform(InferDataTypes())\n",
    "finn_model = finn_model.transform(GiveUniqueNodeNames())\n",
    "finn_model = finn_model.transform(GiveReadableTensorNames())\n",
    "finn_model.cleanup()\n",
    "\n",
    "# extract input quantization thresholds for sw-based quantization\n",
    "# (in case they were not fixed before training)\n",
    "input_mt_node = finn_model.get_nodes_by_op_type(\"MultiThreshold\")[0]\n",
    "input_mt_thresholds = finn_model.get_initializer(input_mt_node.input[1])\n",
    "print(\"input quant thresholds\")\n",
    "print(input_mt_thresholds)\n",
    "\n",
    "# preprocessing: remove input reshape/quantization from graph\n",
    "new_input_node = finn_model.get_nodes_by_op_type(\"Conv\")[0]   # <---- Change this to the name of the node that has its input node the new desired input graph node.\n",
    "new_input_tensor = finn_model.get_tensor_valueinfo(new_input_node.input[0]) #<--- Get the input node that lead to Conv node or whatever node you just changed above\n",
    "old_input_tensor = finn_model.graph.input[0]  # <--- Get the current starting node \n",
    "finn_model.graph.input.remove(old_input_tensor) #<--- Remove the current starting node\n",
    "finn_model.graph.input.append(new_input_tensor) #<--- Make the [Node before the Conv node] the starting node\n",
    "new_input_index = finn_model.get_node_index(new_input_node)\n",
    "del finn_model.graph.node[0:new_input_index] #<--- Delete every node before the new starting node\n",
    "\n",
    "#We dont have softmax node but still run it anyway\n",
    "# postprocessing: remove final softmax node from training\n",
    "softmax_node = finn_model.graph.node[-1]\n",
    "softmax_in_tensor = finn_model.get_tensor_valueinfo(softmax_node.input[0])\n",
    "softmax_out_tensor = finn_model.get_tensor_valueinfo(softmax_node.output[0])\n",
    "finn_model.graph.output.remove(softmax_out_tensor)\n",
    "finn_model.graph.output.append(softmax_in_tensor)\n",
    "finn_model.graph.node.remove(softmax_node)\n",
    "\n",
    "# remove redundant value_info for primary input/output\n",
    "# othwerwise, newer FINN versions will not accept the model\n",
    "if finn_model.graph.input[0] in finn_model.graph.value_info:\n",
    "    finn_model.graph.value_info.remove(finn_model.graph.input[0])\n",
    "if finn_model.graph.output[0] in finn_model.graph.value_info:\n",
    "    finn_model.graph.value_info.remove(finn_model.graph.output[0])\n",
    "\n",
    "# insert topK node in place of the final softmax node\n",
    "# topK plays similar role to softmax\n",
    "# k=1 means it pick only 1 class with highest predictions value\n",
    "finn_model = finn_model.transform(InsertTopK(k=1))\n",
    "\n",
    "# manually set input datatype (not done by brevitas yet)\n",
    "finnonnx_in_tensor_name = finn_model.graph.input[0].name\n",
    "finnonnx_model_in_shape = finn_model.get_tensor_shape(finnonnx_in_tensor_name)\n",
    "finn_model.set_tensor_datatype(finnonnx_in_tensor_name, DataType[\"INT8\"])\n",
    "print(\"Input tensor name: %s\" % finnonnx_in_tensor_name)\n",
    "print(\"Input tensor shape: %s\" % str(finnonnx_model_in_shape))\n",
    "print(\"Input tensor datatype: %s\" % str(finn_model.get_tensor_datatype(finnonnx_in_tensor_name)))\n",
    "\n",
    "# save modified model that is now ready for the FINN compiler\n",
    "finn_model.save(f\"{build_dir}/radio_27ml_tidy.onnx\")\n",
    "print(\"Modified FINN-ready model saved to %s\" % f\"{build_dir}/radio_27ml_tidy.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
